{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "10-Monkey-Species-Image-Recognition.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "mount_file_id": "18oUVufHMetnCj-pGBZLmTzgJrv9YRRsD",
      "authorship_tag": "ABX9TyMRe9XLihevqY4+r2RGXfKZ",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UmutMD/monkey-classification-cnn-mobilenet/blob/main/10_Monkey_Species_Image_Recognition.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About Dataset\n",
        "Content\n",
        "The dataset consists of two files, training and validation. Each folder contains 10 subforders labeled as n0~n9, each corresponding a species form Wikipedia's monkey cladogram. Images are 400x300 px or larger and JPEG format (almost 1400 images). Images were downloaded with help of the googliser open source code.\n",
        "\n",
        "https://www.kaggle.com/datasets/slothkong/10-monkey-species\n",
        "\n",
        "#Label mapping:\n",
        "n0, alouattapalliata n1, erythrocebuspatas\n",
        "n2, cacajaocalvus n3, macacafuscata\n",
        "n4, cebuellapygmea n5, cebuscapucinus\n",
        "n6, micoargentatus n7, saimirisciureus\n",
        "n8, aotusnigriceps n9, trachypithecusjohnii\n",
        "\n",
        "For more information on the monkey species and number of images per class make sure to check monkey_labels.txt file.\n",
        "Aim\n",
        "This dataset is intended as a test case for fine-grain classification tasks, perhaps best used in combination with transfer learning. Hopefully someone can help us expand the number of classes or number of images."
      ],
      "metadata": {
        "id": "fgH094WR7i0n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**data and loading in**\n"
      ],
      "metadata": {
        "id": "1ZMZL7jX-WV9"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "7HeAreTj1cwK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/')\n",
        "\n",
        "from zipfile import ZipFile\n",
        "file_name='/content/drive/MyDrive/Projects/archive.zip'\n",
        "with ZipFile(file_name,'r') as Zip:\n",
        "  Zip.extractall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K0TbrMtN3nFG",
        "outputId": "934eca8f-f9e9-47e5-dbcb-3166c8ac7553"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive/; to attempt to forcibly remount, call drive.mount(\"/content/drive/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Code block [2] did not work as it previously worked with .csv files\n",
        "\n",
        "I extracted folders to the drive to import directly from it."
      ],
      "metadata": {
        "id": "LMgeJ5-g62By"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir = '/content/drive/MyDrive/Projects/training'\n",
        "test_dir = '/content/drive/MyDrive/Projects/validation'"
      ],
      "metadata": {
        "id": "mhfUfbXw4FX8"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dir\n",
        "test_dir"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "0ara_IDL9MYZ",
        "outputId": "ae43bcc3-0c92-4752-810e-5d56b2ed8d27"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/content/drive/MyDrive/Projects/validation'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE= 16\n",
        "\n",
        "IMAGE_HEIGHT =224\n",
        "IMAGE_WIDTH = 224\n"
      ],
      "metadata": {
        "id": "3BJrd0YX-JCo"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "dataset generator for train"
      ],
      "metadata": {
        "id": "suQ1qxMa-sQj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = tf.keras.preprocessing.image.ImageDataGenerator (\n",
        "    rescale = 1./255,\n",
        "    rotation_range =90,\n",
        "    width_shift_range = 0.8,\n",
        "    height_shift_range = 0.5,\n",
        "    validation_split =0.3\n",
        ")\n",
        "\n",
        "test_generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255)"
      ],
      "metadata": {
        "id": "bib2kFpa-vtY"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = train_generator.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size = ( IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "      batch_size = BATCH_SIZE,\n",
        "      subset= 'training'\n",
        ")\n",
        "\n",
        "validation_data = train_generator.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size = ( IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "      batch_size = BATCH_SIZE,\n",
        "      subset= 'validation'\n",
        ")\n",
        "\n",
        "test_data = train_generator.flow_from_directory(\n",
        "      train_dir,\n",
        "      target_size = ( IMAGE_HEIGHT, IMAGE_WIDTH),\n",
        "      batch_size = BATCH_SIZE\n",
        ")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5jIsLg5xBzMF",
        "outputId": "2b26dde8-2603-4a23-9a4f-880cbb60521c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 769 images belonging to 1 classes.\n",
            "Found 329 images belonging to 1 classes.\n",
            "Found 1098 images belonging to 1 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model building\n"
      ],
      "metadata": {
        "id": "DBV7AEuyDrVm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pretrained = tf.keras.applications.MobileNet(\n",
        "    weights = 'imagenet',\n",
        "    include_top =False,\n",
        "    pooling ='avg',\n",
        "    input_shape = (IMAGE_HEIGHT, IMAGE_WIDTH, 3)\n",
        ")\n",
        "pretrained.trainable =False"
      ],
      "metadata": {
        "id": "B5DPqTdJDt4m"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "p_qxBzoM2CF8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inputs = tf.keras.Input (shape = (IMAGE_HEIGHT, IMAGE_WIDTH,3))\n",
        "\n",
        "x = pretrained(inputs, training =False)\n",
        "x = tf.keras.layers.Dense (1024, activation='relu')(x)\n",
        "x = tf.keras.layers.Dense(512, activation = 'relu')(x)\n",
        "x = tf.keras.layers.Dense (512, activation ='relu')(x)\n",
        "outputs = tf.keras.layers.Dense (10, activation=  'softmax')(x)\n",
        "\n",
        "model = tf.keras.Model(inputs, outputs)\n"
      ],
      "metadata": {
        "id": "HeWkMboD1zm2"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AyBdGVgg3hC_",
        "outputId": "62ee2cce-0b55-448b-a9a6-3dd02bd1ba66"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_6 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " mobilenet_1.00_224 (Functio  (None, 1024)             3228864   \n",
            " nal)                                                            \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1024)              1049600   \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 512)               524800    \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 512)               262656    \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                5130      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 5,071,050\n",
            "Trainable params: 1,842,186\n",
            "Non-trainable params: 3,228,864\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer = 'adam',\n",
        "    loss= 'BinaryCrossentropy',\n",
        "    metrics = [ 'accuracy']\n",
        "\n",
        "\n",
        ")\n",
        "\n",
        "EPOCHS= 20\n",
        "\n",
        "history = model.fit (\n",
        "      train_data,\n",
        "      validation_data = validation_data,\n",
        "      batch_size = BATCH_SIZE,\n",
        "      epochs=EPOCHS,\n",
        "      callbacks =[\n",
        "                  tf.keras.callbacks.EarlyStopping(\n",
        "                      monitor ='val_loss',\n",
        "                      patience =3,\n",
        "                      restore_best_weights = True,\n",
        "                      verbose=1\n",
        "\n",
        "                  )\n",
        "\n",
        "      ],\n",
        "      verbose =2\n",
        "\n",
        "\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VI5a2mHV3mN5",
        "outputId": "f4196341-5b5e-4319-fc5b-396650ad4634"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(test_data)"
      ],
      "metadata": {
        "id": "gA0CkfIx5NIq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}